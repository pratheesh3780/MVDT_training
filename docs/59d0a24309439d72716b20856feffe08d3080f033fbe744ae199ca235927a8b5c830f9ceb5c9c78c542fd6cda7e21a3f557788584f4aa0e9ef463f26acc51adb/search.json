[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"\n\n\nWelcome “Multivariate Data Analysis Tools Agricultural Research” training manual, specialized resource tailored agricultural researchers leveraging R programming language data analysis. realm agricultural research, multidimensional datasets hold keys improving crop yields, soil health, sustainable farming practices, manual equips essential knowledge skills unlock actionable insights. fundamental concepts practical applications, training explores techniques like PCA, Factor Analysis, Cluster Analysis, , within context agricultural research. power R fingertips, ’ll harness full potential agricultural data, making informed decisions drive innovation advancement field agriculture.\n\ncontent manual carefully designed ensure presented simple straightforward manner, making accessible individuals levels expertise. aim demystify complex concepts, providing clarity ease understanding anyone, regardless background, can grasp apply fundamental principles multivariate data analysis agricultural research confidence.\n","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"\n\n\nNote: training Manual published MeLoN (Module e-Learning & Online Notes) Department Agricultural Statistics . online version book free read .\n\nfeedback, please feel free contact Dr.Pratheesh P. Gopinath. E-mail: pratheesh.pg@kau.Thank !\n","code":""},{"path":"r-and-r-studio.html","id":"r-and-r-studio","chapter":"1 R and R studio","heading":"1 R and R studio","text":"training program tailored equip skills needed multivariate data analysis using R RStudio. introductory section, provide brief overview guide process installing R RStudio.","code":""},{"path":"r-and-r-studio.html","id":"r","chapter":"1 R and R studio","heading":"1.1 R","text":"R programming language statistical computing graphics supported R Core Team R Foundation Statistical Computing. Created statisticians Ross Ihaka Robert Gentleman. R implementation S programming language. R used among data miners, bioinformaticians statisticians data analysis developing statistical software. Users created packages augment functions R language.\nAccording user surveys studies scholarly literature databases, R one commonly used programming languages used data mining. official R software environment open-source free software environment within GNU package, available GNU General Public License. written primarily C, Fortran, R (partially self-hosting). R command line interface. Multiple third-party graphical user interfaces also available, RStudio, integrated development environment.\nFigure 1.1: R logo\n","code":""},{"path":"r-and-r-studio.html","id":"rstudio","chapter":"1 R and R studio","heading":"1.2 Rstudio","text":"RStudio integrated development environment (IDE) R. includes console, syntax-highlighting editor supports direct code execution, well tools plotting, history, debugging workspace management. RStudio available open source commercial editions runs desktop (Windows, Mac, Linux) browser connected RStudio Server. RStudio free open-source integrated development environment (IDE) R, programming language statistical computing graphics. JJ Allaire, creator programming language ColdFusion, founded RStudio. RStudio available two editions: RStudio Desktop, program run locally regular desktop application; RStudio Server, allows accessing RStudio using web browser running remote Linux server.RStudio written C++ programming language uses Qt framework graphical user interface. Work RStudio started around December 2010, first public beta version (v0.92) officially announced February 2011.\nFigure 1.2: R studio logo\nTypical RStudio window four panes explained \nFigure 1.3: R studio window\nConsoleThis action happens. authentic R code typed ‘>’ prompt executed pressing ‘Enter’ generate output. going type single call function start app data analysis.Source EditorThis R scripts (collection code) can created edited. New R script can opened clicking File –> New File –> R Script using short cut ctrl+shift+N. can type codes . run code console execute, place cursor line code written press ctrl+enter highlight code wish evaluate clicking “Run” button top right Source. can save R codes, written script.Environment|History|ConnectionsAll data objects (vectors, matrices, dataframes) defined current R session listed Environment tab panel. data objects, may also examine details like quantity observations rows. clickable options available tab, Import Dataset, launch graphical user interface (GUI) inputting data R.panel’s History tab provides history code previously evaluated Console.Environment / History panel helpful become accustomed R. However, can ignore right now. can simply just reduce window clicking minimise button panel’s upper right corner wish clear space screen.Files|Plots|Packages|Help|ViewerYou can find collection useful information Files|Plots|Packages|Help panel. Let’s examine tab detail:\n- file directory hard disc accessible files panel. can utilise “Files” panel set working directory clicking “” “Set Working Directory” ’ve navigated folder wish read save files.plots displayed Plots panel. buttons export plot pdf jpg open plot separate window.\ninterested install button pane, install packages required analysis.","code":""},{"path":"r-and-r-studio.html","id":"installing-r","chapter":"1 R and R studio","heading":"1.3 Installing R","text":"Follow steps correct order installation R","code":""},{"path":"r-and-r-studio.html","id":"first-install-r-latest-version","chapter":"1 R and R studio","heading":"1.3.1 First install R latest version","text":"install R Windows OS:Go CRAN website.Click “Download R Windows”.Click “install R first time”.\nClick “Download R-4.3.1 windows” link download R executable (.exe) file.(time writing manual R version 4.3.1, may change future)downloading file. Run R executable file double clicking downloaded file start installation, allow app make changes device.Select installation language.Follow installation instructions.Click next wait installation complete.Click “Finish” exit complete installation setup.can now run R start menu shortcut created desktop","code":""},{"path":"r-and-r-studio.html","id":"installing-rstudio","chapter":"1 R and R studio","heading":"1.4 Installing Rstudio","text":"installing latest version R. Go Rstudio website.\nFigure 1.4: FALSE\nNow like completed installation R, complete installation setup Rstudio. installation can now run R start menu shortcut created desktop.Now ready explore world data analysis unleash potential R RStudio unlock valuable insights datasets. Happy Statistics R!","code":""},{"path":"r-and-r-studio.html","id":"the-above-descriptions-are-sourced-from","chapter":"1 R and R studio","heading":"The above descriptions are sourced from:","text":"R Project Statistical ComputingRStudioWikipedia R (programming language)Wikipedia RStudio","code":""},{"path":"import.html","id":"import","chapter":"2 Importing data files in R","heading":"2 Importing data files in R","text":"previous chapter discussed basics R\nprogramming including installation, launching, basic data types \narithmetic functions. , learn import data R. \nimportant ensure data well prepared importing\nR avoid errors.","code":""},{"path":"import.html","id":"preparing-your-file","chapter":"2 Importing data files in R","heading":"2.1 Preparing your file","text":"File can prepared MS ExcelFile can prepared MS ExcelUse first row column headers (column names). Generally,\ncolumns represent variables.Use first row column headers (column names). Generally,\ncolumns represent variables.Use first column row names. Generally rows represent\nobservations.Use first column row names. Generally rows represent\nobservations.Make sure row name unique. case \nanalysis experiments , row name treatment name,\nrepeated replicationMake sure row name unique. case \nanalysis experiments , row name treatment name,\nrepeated replicationColumn names compatible R naming conventions.","code":""},{"path":"import.html","id":"naming-conventions","chapter":"2 Importing data files in R","heading":"2.1.1 Naming conventions:","text":"Avoid names blank spaces. Bad column name Sepal width; Good\nconvention Sepal_widthAvoid names blank spaces. Bad column name Sepal width; Good\nconvention Sepal_widthAvoid names special symbols: ?, $, *, +, #, (, ), -, /, }, {,\n|, >, < etc. underscore can used.Avoid names special symbols: ?, $, *, +, #, (, ), -, /, }, {,\n|, >, < etc. underscore can used.Avoid beginning variable names number. Use letter instead.\nGood column names: obs_100m x100m. Bad column name: 100mAvoid beginning variable names number. Use letter instead.\nGood column names: obs_100m x100m. Bad column name: 100mColumn names must unique. Duplicated names allowed.Column names must unique. Duplicated names allowed.R case sensitive. means Name, NAME name, naMe \ntreated different.R case sensitive. means Name, NAME name, naMe \ntreated different.Avoid blank rows dataAvoid blank rows dataDelete comments fileDelete comments fileReplace missing values NA (denotes Available)Replace missing values NA (denotes Available)column containing date, use four digit format.\nGood format: 01/01/2016. Bad format: 01/01/16If column containing date, use four digit format.\nGood format: 01/01/2016. Bad format: 01/01/16A final good looking file\nFigure 2.1: example file\n","code":""},{"path":"import.html","id":"saving-file","chapter":"2 Importing data files in R","heading":"2.1.2 Saving file","text":"recommend save file .csv (comma separated value file)\nformat.CSV?usual file save MS Excel saved XLS files XLSX\nfiles. Workbook files Microsoft Excel 97 2003 known \nXLS files. XLSX extension used later versions Excel. \ndata worksheets workbook, including formatting,\ncharts, graphics, calculations, , contained XLS \nXLSX file formats.Comma Separated Values (CSV) format plain text format \nvalues separated commas, whereas Excel Sheets binary file\nformat (XLS) contains information worksheets file,\nincluding content formatting. spreadsheet programme,\nincluding Microsoft Excel, Open Office, Google Sheets, etc., can open\nCSV files. straightforward text editor can also used open CSV\nfiles. straightforward compatible majority \nplatforms, prevalent well-liked file format storing\naccessing data. certain drawbacks simplicity.\nCSV files can contain single sheet without formatting \nformulas.CSV files supported almost data upload interfaces,\nExcel (XLS XLSX) file types preferable storing \ncomplicated data. CSV file format may advantageous \nintend move data platforms export import \ninterfaces.","code":""},{"path":"import.html","id":"how-to-save-as-csv","chapter":"2 Importing data files in R","heading":"2.1.3 How to save as csv","text":"\"File name\" section \"Save \" tab, can select\n\"Save type\" change \"CSV (Comma delimited) (*.csv).\nFigure 2.2: save csv\n\nFigure 2.3: save csv (1)\n","code":""},{"path":"import.html","id":"importing-data-set-in-rstudio","chapter":"2 Importing data files in R","heading":"2.2 Importing Data set in Rstudio","text":"import csv file Rstudioclick File click Import Dataset select Text (base)\nFigure 2.4: Importing data set\nSelect file click open\nFigure 2.5: Import Dataset dialogue box\nImport Dataset dialogue box can change name \ndataset Box Name. Heading radio button default\n‘yes’. Click import. dataset now imported ready \nwork .","code":""},{"path":"import.html","id":"alternate-methods","chapter":"2 Importing data files in R","heading":"2.2.1 Alternate methods","text":"","code":""},{"path":"import.html","id":"importing-csv-files","chapter":"2 Importing data files in R","heading":"2.2.1.1 Importing csv files","text":"Data can also imported using read.csv() function R.\nread.csv('path file')","code":"\n# example\n\nmy_data<-read.csv(file = 'csv/usarrests.csv')\n\n# here now the data set usarrests.csv stored in folder csv is stored in the name my_data\n\n# You can now directly do operations on the my_data\n\nsummary(my_data)##       X                 Murder          Assault         UrbanPop    \n##  Length:50          Min.   : 0.800   Min.   : 45.0   Min.   :32.00  \n##  Class :character   1st Qu.: 4.075   1st Qu.:109.0   1st Qu.:54.50  \n##  Mode  :character   Median : 7.250   Median :159.0   Median :66.00  \n##                     Mean   : 7.788   Mean   :170.8   Mean   :65.54  \n##                     3rd Qu.:11.250   3rd Qu.:249.0   3rd Qu.:77.75  \n##                     Max.   :17.400   Max.   :337.0   Max.   :91.00  \n##       Rape      \n##  Min.   : 7.30  \n##  1st Qu.:15.07  \n##  Median :20.10  \n##  Mean   :21.23  \n##  3rd Qu.:26.18  \n##  Max.   :46.00"},{"path":"import.html","id":"importing-excel-files","chapter":"2 Importing data files in R","heading":"2.2.1.2 Importing excel files","text":"import xlsx file, need package xlsx","code":"library(xlsx)  \n\ndf <-read.xlsx(\"path/file.xlsx\", n)\n\n# n is n-th worksheet to import"},{"path":"principal-component-analysis-pca.html","id":"principal-component-analysis-pca","chapter":"3 Principal Component Analysis (PCA)","heading":"3 Principal Component Analysis (PCA)","text":"","code":""},{"path":"principal-component-analysis-pca.html","id":"what-is-pca","chapter":"3 Principal Component Analysis (PCA)","heading":"3.1 What is PCA?","text":"Principal component analysis (PCA) technique transforms high-dimensions data lower-dimensions retaining much information possible. PCA invented 1909 Karl Pearson, analogue principal axis theorem mechanics; later independently developed named Harold Hotelling 1930s.Drawing meaningful inferences high-dimensional data can challenging, humans naturally excel visualizing comprehending information two dimensions. PCA, powerful technique, aids transforming multi-dimensional data manageable form reducing dimensionality. simplification facilitates easier visualization analysis, ultimately enhancing ability extract valuable insights complex datasets.PCA valuable tool social science agricultural research. works transforming multi-dimensional data lower-dimensional space retaining much variance data possible. essence, PCA identifies significant dimensions “principal components” data, effectively reducing complexity.\nidea PCA simple — reduce number variables data set, preserving much information possible.","code":""},{"path":"principal-component-analysis-pca.html","id":"when-to-use-pca","chapter":"3 Principal Component Analysis (PCA)","heading":"3.2 When to Use PCA","text":"Dimensionality Reduction: Use PCA high-dimensional dataset many features (variables) want reduce dimensionality. can help cases many variables work efficiently.Data Visualization: PCA effective need visualize high-dimensional data. projecting data onto lower-dimensional space, can create scatter plots, heatmaps, visualizations easier interpret.Minimum data set: Principal components can used eliminate data sets identify minimum data set experimentation.Noise Reduction: dataset contains noisy redundant features, PCA can help capturing important information eliminating less relevant components.Multicollinearity: dataset multicollinearity issues (high correlations variables), PCA can help reduce interdependencies, making models stable interpretable.Sample size (n) least equal number dimensions (n ≥ p)","code":""},{"path":"principal-component-analysis-pca.html","id":"when-not-to-use-pca","chapter":"3 Principal Component Analysis (PCA)","heading":"3.3 When Not to Use PCA","text":"sample size less number dimensions (n < p)Non-Linear Relationships: PCA based linear transformations may effective data contains complex non-linear relationships. cases, techniques like kernel PCA non-linear dimensionality reduction methods might appropriate.Small Dimensionality: already low-dimensional dataset important variables, applying PCA might provide significant benefits even lead information loss.Loss Variability Information: PCA aims maximize variance capture, may desirable cases. preserving characteristics data important (e.g., categorical information), dimensionality reduction techniques considered.","code":""},{"path":"principal-component-analysis-pca.html","id":"how-pca-is-done","chapter":"3 Principal Component Analysis (PCA)","heading":"3.4 How PCA is done","text":"training program, primarily focused practical application PCA rather delving theoretical aspects. aim explore PCA can effectively utilized understand interpret results meaningful manner. usual procedure performing follows information:-\n* Standardize range continuous initial variables\n* Compute covariance matrix identify correlations\n* Compute eigen vectors eigen values covariance matrix identify principal components\n* Create feature vector decide principal components keep\n* Recast data along principal components axes","code":""},{"path":"principal-component-analysis-pca.html","id":"what-is-principal-component","chapter":"3 Principal Component Analysis (PCA)","heading":"3.5 What is Principal Component","text":"Principal components new variables constructed linear combinations initial variables. combinations done way new variables (.e. principal components) uncorrelated information within initial variables included first components. , idea 10-dimensional data gives 10 principal components, PCA tries put maximum possible information first component, maximum remaining information second .example scree plot shown can see 5 principal components 5-dimensional data corresponding variance explained.\nFigure 3.1: Scree Plot: Principal components percentage variance explained\n","code":""},{"path":"principal-component-analysis-pca.html","id":"how-pca-constructs-the-principal-components","chapter":"3 Principal Component Analysis (PCA)","heading":"3.6 How PCA Constructs the Principal Components","text":"Number principal components equal number variables data, principal components constructed manner first principal component accounts largest possible variance data set. example, see Figure 1.2 , can see scatter plot assumed data set, can guess first principal component ? Yes, ’s approximately line matches purple marks goes origin ’s line projection points (red dots) spread . mathematically speaking, ’s line maximizes variance (average squared distances projected points (red dots) origin).\nFigure 3.2: Concept PCA\nlines (PCs) identified using linear algebra concepts Eigen vectors eigen values calculated covariance matrix order determine principal components data. going much theoretical details.","code":""},{"path":"principal-component-analysis-pca.html","id":"practical-example","chapter":"3 Principal Component Analysis (PCA)","heading":"3.7 PRACTICAL EXAMPLE","text":"using Usarrests dataset R explain PCA coming sessions.“USarrests” dataset R built-dataset offers insights crime arrests across 50 states United States 1973. comprises four key variables: murder rate, assault rate, percentage population living urban areas, rape rate.can View download datasets ","code":""},{"path":"principal-component-analysis-pca.html","id":"analysis","chapter":"3 Principal Component Analysis (PCA)","heading":"3.8 Analysis","text":"First prepare data set save csv file. import data set R. See 2\">chapter see save csv file import R. can directly use code import dataset computer R.copy path system data please change format “C:/Users/HP/Documents/” code.\ndataset looks like importing R.\n(#fig:data_imp)Data set importing R Rstudio\nusing package factoextra performing analysisInstall required packages:Follow codes PCA analysis","code":"\ndata <- read.csv(\"path to your file\", row.names=1)\ninstall.packages(\"factoextra\")  \nlibrary(factoextra)\n#storing your dataset to the variable data\ndata <- read.csv(\"csv/usarrests.csv\", row.names=1)\n\n#this will display the first 6 rows of your data\nhead(data, n = 6)##            Murder Assault UrbanPop Rape\n## Alabama      13.2     236       58 21.2\n## Alaska       10.0     263       48 44.5\n## Arizona       8.1     294       80 31.0\n## Arkansas      8.8     190       50 19.5\n## California    9.0     276       91 40.6\n## Colorado      7.9     204       78 38.7\n# Do PCA using prcomp function in factoextra\npca_res <- prcomp(data, scale = TRUE)\n# scale = TRUE will standardise the variables (x-mean(x)/sd(x))\nsummary(pca_res)## Importance of components:\n##                           PC1    PC2     PC3     PC4\n## Standard deviation     1.5749 0.9949 0.59713 0.41645\n## Proportion of Variance 0.6201 0.2474 0.08914 0.04336\n## Cumulative Proportion  0.6201 0.8675 0.95664 1.00000"},{"path":"principal-component-analysis-pca.html","id":"deciding-on-the-number-of-pcs","chapter":"3 Principal Component Analysis (PCA)","heading":"3.9 Deciding on the number of PCs","text":"","code":""},{"path":"principal-component-analysis-pca.html","id":"scree-plot","chapter":"3 Principal Component Analysis (PCA)","heading":"3.9.1 Scree Plot","text":"scree plot helps decide many principal components retain PCA analysis. choice number components can vary depending specific goals, ’s often based combination statistical criteria, explained variance elbow point, well domain knowledge interpretability.key inferences can make plot:Explained Variance: scree plot displays proportion total variance explained principal component. Inferences can made examining much variance explained component. components left contribute variance, right contribute less.Elbow Point: Look “elbow” point explained variance sharply decreases. often good indicator number principal components retain. point just explained variance starts level can suitable choice. ’s point adding components doesn’t explain much additional variance.Cumulative Variance: can also examine cumulative explained variance. scree plot may show cumulative curve increases components added. can look point cumulative variance reaches satisfactory level (e.g., 70%, 80%, 90%) determine number components retain.Interpretability: Consider interpretability components. Sometimes, might choose retain components even explain less variance meaningful interpretations context.Domain Knowledge: Always consider domain subject matter knowledge deciding number components retain. Sometimes, context analysis may dictate number components practically meaningful.","code":"\n# Visualize eigenvalues (scree plot)\nplot1 <- fviz_eig(pca_res,addlabels = TRUE)\nplot1\n# Drawing an elbow point if needed\npca.var =pca_res$sdev ^2\nvar.ratio=pca.var/sum(pca.var)\nplot(var.ratio , xlab=\" Principal Component \", ylab=\" Proportion of\nVariance Explained \", ylim=c(0,1) ,type=\"b\")"},{"path":"principal-component-analysis-pca.html","id":"eigen-values","chapter":"3 Principal Component Analysis (PCA)","heading":"3.9.2 Eigen Values","text":"“Eigenvalues” represent variance explained principal component (PC) PCA. Percentage variance ratio eigen value principal component sum eigen values PCs. important note first two PCs atleast explain 80% variance data.Eigenvalues can used determine number principal components retain PCA (Kaiser 1961):eigenvalue > 1 indicates PCs account variance accounted one original variables standardized data. commonly used cutoff point PCs retained. holds true data standardized.can also select number principal components Principal Component Analysis (PCA) based desired level explained variance. instance, want retain 80% total variance explained, can choose number components achieves level.","code":"\n# Eigenvalues\neig.val <- get_eigenvalue(pca_res)\neig.val##       eigenvalue variance.percent cumulative.variance.percent\n## Dim.1  2.4802416        62.006039                    62.00604\n## Dim.2  0.9897652        24.744129                    86.75017\n## Dim.3  0.3565632         8.914080                    95.66425\n## Dim.4  0.1734301         4.335752                   100.00000\n#Now we will take the PCA results keeping first two pricipal components only\nres.pca <- prcomp(USArrests, scale = TRUE, rank =2)\n#here rank =2 will keep only two PCs"},{"path":"principal-component-analysis-pca.html","id":"accessing-the-pca-results","chapter":"3 Principal Component Analysis (PCA)","heading":"3.10 Accessing the PCA results","text":"Please note results discussed Dim1 , Dim2 etc denotes Principal Component1(PC1), PC2 etc respectively. now discuss terms PCA can interpreted get meaningful insights.","code":""},{"path":"principal-component-analysis-pca.html","id":"pc-loadings","chapter":"3 Principal Component Analysis (PCA)","heading":"3.10.1 PC Loadings","text":"Loadings coefficients linear combination predicting variable (standardized) components. Loadings represent weights assigned original variable linear combination forms principal component. weights indicate importance variable creating component. statistical language loadings eigenvectors scaled square roots respective eigenvalues.Positive loadings indicate positive relationship variable component, suggesting increase variable associated increase component’s value. Negative loadings indicate negative relationship, meaning increase variable corresponds decrease component’s value. magnitude loading reflects strength relationship. Larger loadings indicate variable substantial impact component. Loadings typically standardized mean 0 standard deviation 1, ensuring variables different scales directly comparable.first loading vector places approximately equal weight Assault, Murder, Rape, much less weight UrbanPop. Hence component roughly corresponds measure overall rates serious crimes. loadings negative can assume states scoring lesser values PC1 higher crime rate.","code":"\n#getting PC loadings\nres.pca$rotation##                 PC1        PC2\n## Murder   -0.5358995 -0.4181809\n## Assault  -0.5831836 -0.1879856\n## UrbanPop -0.2781909  0.8728062\n## Rape     -0.5434321  0.1673186"},{"path":"principal-component-analysis-pca.html","id":"variable-coordinates","chapter":"3 Principal Component Analysis (PCA)","heading":"3.10.2 Variable coordinates","text":"coordinates provides insights relative positions variables PCA space relate principal components geometrically. Absolute value measures gives strength association variable particular PCs. can avoid final tables, presenting results. coordinates already represented biplots.","code":"\n# Results for Variables\nres.var <- get_pca_var(res.pca)\nres.var$coord          # Coordinates  ##               Dim.1      Dim.2      Dim.3       Dim.4\n## Murder   -0.8439764 -0.4160354 -0.3200012 -0.17415116\n## Assault  -0.9184432 -0.1870211 -0.3482359 -0.07828649\n## UrbanPop -0.4381168  0.8683282 -0.1661159  0.36347960\n## Rape     -0.8558394  0.1664602 -0.3244991  0.06967974"},{"path":"principal-component-analysis-pca.html","id":"variable-contributions","chapter":"3 Principal Component Analysis (PCA)","heading":"3.10.3 Variable contributions","text":"measures provides percentage contributions variable principal component. indicates proportion variance explained variable principal component. Higher values suggest variable substantial influence formation respective component. helps identify variables contribute significantly variance explained component useful variable selection interpretation.contributions reflect idea loadings convey. can see higher contribution Assault, Murder, Rape PC1 higher contribution urban population PC2.","code":"\nres.var$contrib        # Contributions to the PCs  ##              Dim.1     Dim.2     Dim.3     Dim.4\n## Murder   28.718825 17.487524 28.718825 17.487524\n## Assault  34.010315  3.533859 34.010315  3.533859\n## UrbanPop  7.739016 76.179065  7.739016 76.179065\n## Rape     29.531844  2.799553 29.531844  2.799553"},{"path":"principal-component-analysis-pca.html","id":"cos2-representation","chapter":"3 Principal Component Analysis (PCA)","heading":"3.11 cos2 representation","text":"Cosine Squared (Cos²) Values: cos2 values provides cosine squared values variable respect principal component. Cosine squared values measure much variable’s variance explained corresponding principal component. cos2 values typically range 0 1. value 1 indicates variable perfectly aligned principal component, meaning variable’s entire variance explained component. value 0 indicates variable orthogonal component.\nHigher cos2 values indicate variable well-represented principal component. variables contribute significantly explanation variance along component. Lower values suggest variable less alignment component less influential explaining variance.can exclude values final table presenting results.","code":"\nres.var$cos2           # Quality of representation ##              Dim.1     Dim.2      Dim.3       Dim.4\n## Murder   0.7122962 0.1730854 0.10240075 0.030328628\n## Assault  0.8435380 0.0349769 0.12126826 0.006128774\n## UrbanPop 0.1919463 0.7539938 0.02759448 0.132117419\n## Rape     0.7324611 0.0277090 0.10529968 0.004855266"},{"path":"principal-component-analysis-pca.html","id":"measures-of-indviduals","chapter":"3 Principal Component Analysis (PCA)","heading":"3.11.1 Measures of Indviduals","text":"Similar measures calculated individuals also. individuals higher values PCs can identified insights can drawn based .\nexample states high negative values PC1 high crime rate states high values PC2 higher level urbanization.\nprincipal components scores vector 50 states(indviduals) can viewed using following code.California, Nevada Florida, high crime rates large negative scores first component, states like North Dakota, positive scores first component, low crime rates.California also high score second component, indicating high level urbanization, opposite true states like Mississippi.can find contributions, cos2 coordinates individuals, depth analysis required study, using code .","code":"\n# principal components scores vector for all 50 states(indviduals)\nres.pca$x##                        PC1         PC2\n## Alabama        -0.97566045 -1.12200121\n## Alaska         -1.93053788 -1.06242692\n## Arizona        -1.74544285  0.73845954\n## Arkansas        0.13999894 -1.10854226\n## California     -2.49861285  1.52742672\n## Colorado       -1.49934074  0.97762966\n## Connecticut     1.34499236  1.07798362\n## Delaware       -0.04722981  0.32208890\n## Florida        -2.98275967 -0.03883425\n## Georgia        -1.62280742 -1.26608838\n## Hawaii          0.90348448  1.55467609\n## Idaho           1.62331903 -0.20885253\n## Illinois       -1.36505197  0.67498834\n## Indiana         0.50038122  0.15003926\n## Iowa            2.23099579  0.10300828\n## Kansas          0.78887206  0.26744941\n## Kentucky        0.74331256 -0.94880748\n## Louisiana      -1.54909076 -0.86230011\n## Maine           2.37274014 -0.37260865\n## Maryland       -1.74564663 -0.42335704\n## Massachusetts   0.48128007  1.45967706\n## Michigan       -2.08725025  0.15383500\n## Minnesota       1.67566951  0.62590670\n## Mississippi    -0.98647919 -2.36973712\n## Missouri       -0.68978426  0.26070794\n## Montana         1.17353751 -0.53147851\n## Nebraska        1.25291625  0.19200440\n## Nevada         -2.84550542  0.76780502\n## New Hampshire   2.35995585  0.01790055\n## New Jersey     -0.17974128  1.43493745\n## New Mexico     -1.96012351 -0.14141308\n## New York       -1.66566662  0.81491072\n## North Carolina -1.11208808 -2.20561081\n## North Dakota    2.96215223 -0.59309738\n## Ohio            0.22369436  0.73477837\n## Oklahoma        0.30864928  0.28496113\n## Oregon         -0.05852787  0.53596999\n## Pennsylvania    0.87948680  0.56536050\n## Rhode Island    0.85509072  1.47698328\n## South Carolina -1.30744986 -1.91397297\n## South Dakota    1.96779669 -0.81506822\n## Tennessee      -0.98969377 -0.85160534\n## Texas          -1.34151838  0.40833518\n## Utah            0.54503180  1.45671524\n## Vermont         2.77325613 -1.38819435\n## Virginia        0.09536670 -0.19772785\n## Washington      0.21472339  0.96037394\n## West Virginia   2.08739306 -1.41052627\n## Wisconsin       2.05881199  0.60512507\n## Wyoming         0.62310061 -0.31778662\nres.ind <- get_pca_ind(res.pca)\nres.ind$coord          # Coordinates\nres.ind$contrib        # Contributions to the PCs\nres.ind$cos2           # Quality of representation "},{"path":"principal-component-analysis-pca.html","id":"biplot-indviduals","chapter":"3 Principal Component Analysis (PCA)","heading":"3.12 Biplot (Indviduals)","text":"“Biplot Individuals” graphical representation used Principal Component Analysis (PCA) multivariate statistical methods visualize individual data points observations related underlying patterns variables dataset. examining biplot, analysts researchers can gain insights various aspects data, including clustering patterns among individual observations.Interpretation Biplot indvidualsIndividuals’ Position: point biplot represents individual observation dataset. positions points plot show individual relates principal components. Individuals closer plot similar terms relationships principal components.Color Coding: points representing individuals may color-coded based “cos2” values, indicate quality representation individual plot. Higher “cos2” values indicate individual’s position plot strongly associated principal components.“cos2” Biplot:\ncontext PCA biplot, “cos2” represents square cosine angle individual’s position (point) variable’s arrow plot. quantifies quality representation individual plot.High “cos2” values suggest individual’s position plot well-represented variables principal components.High “cos2” values suggest individual’s position plot well-represented variables principal components.Low “cos2” values suggest individual’s position may well-represented may noisy plotLow “cos2” values suggest individual’s position may well-represented may noisy plot","code":"\n#Graph of individuals. Individuals with a similar profile are grouped together (Biplot)\nbiplot1<-fviz_pca_ind(res.pca,\n             col.ind = \"cos2\", # Color by the quality of representation\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE     # Avoid text overlapping\n             )\nbiplot1"},{"path":"principal-component-analysis-pca.html","id":"biplot-variables","chapter":"3 Principal Component Analysis (PCA)","heading":"3.13 Biplot (variables)","text":"biplot, variables represented arrows vectors, plot allows examination variables associated principal components.Interpretation PCA Variable BiPlot:Variable Positions: point variable plot represents variable dataset. positions points plot show variable relates principal components. Variables closer plot similar terms relationships principal components.Direction Arrows: Arrows variable plot represent variables contribution principal components. direction arrows indicates variable associated principal component. Variables pointing direction positively correlated corresponding component, pointing opposite directions negatively correlated. helps understand variables move direction component move opposite direction.Arrow Length: length arrows indicates strength relationship variables principal components. Longer arrows represent variables higher contribution component.Color Coding: points representing variables may color-coded based contributions principal components. Higher contributions typically associated darker color.","code":"\n#Graph of variables. \nbiplot2<-fviz_pca_var(res.pca,\n             col.var = \"contrib\", # Color by contributions to the PC\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE     # Avoid text overlapping\n             )\nbiplot2"},{"path":"principal-component-analysis-pca.html","id":"biplot-indviduals-and-variables","chapter":"3 Principal Component Analysis (PCA)","heading":"3.14 Biplot (Indviduals and variables)","text":"biplot combines individual data points represented points plot variables represented arrows vectors. provides powerful way assess relationships individual observations variables, offering insights patterns, clusters, associations within data. examining positions individuals directions variable vectors, analysts can gain holistic understanding data’s underlying structure, making valuable tool dimensionality reduction data exploration.Interpretation PCA BiPlot (Individuals Variables):Distance Origin (Center): distance individual point origin (center) plot represents contribution explained variance principal components. Points origin stronger influence principal components, points closer origin weaker influence. words, individuals origin better represented principal components.Projection onto Arrows: position individual point relative arrows tells individual influenced variables. individual point projected close tip arrow, indicates individual’s profile strongly influenced particular variable represented arrow.Alignment Points Arrows: direction arrows position individuals align, suggests variables individuals positively correlated corresponding principal component. words, variables point direction individual points contribute positively principal component.Opposite Direction: individual point arrow opposite directions, indicates negative correlation individual variable, implying variable contributes negatively principal component individual.summary, relationship position individuals direction arrows PCA biplot provides insights individual observations relate variables principal components. biplot helps understand strength direction relationships, allowing identify variables influence components individuals affected variables.biplot shows 50 states mapped according 2 principal components. vectors PCA 4 variables also plotted.states California, Nevada Florida,seen towards extreme left, indicating high negative value PC1. .e. states high crime rates.states like North Dakota seen towards right high positive scores first component, indicative low crime rates.general can divide quadrants biplot example follows:States Quadrant towards right: Low crime rate high urbanizationStates Quadrant II towards left: High crime rate high urbanizationStates Quadrant III towards bottom left: High crime rate low urbanizationStates Quadrant IV towards bottom right: Low crime rate low urbanizationTowards center: States moderate crime rate urbanization\nFigure 3.3: Quadrants biplot\nUsing code can save plots required resolution. changing resolution change value res code .","code":"\n#Biplot of individuals and variables\nbiplot3<- fviz_pca_biplot(res.pca, repel = TRUE,\n                col.var = \"#2E9FDF\", # Variables color\n                col.ind = \"#696969\"  # Individuals color\n                )\nbiplot3\n# Save the scree plot as a PNG file\n  png(\"eigenvalues_plot.png\", width = 800, height = 600, units = \"px\", res = 100)\n  plot1\n  dev.off() # Close the PNG device  \n\n  # Save the biplot of indviduals a PNG file\n  png(\"bi_plot.png\", width = 800, height = 600, units = \"px\", res = 100)\n  biplot1\n  dev.off() # Close the PNG device  \n  \n  # Save the biplot of variables a PNG file\n  png(\"bi_plot2.png\", width = 800, height = 600, units = \"px\", res = 100)\n  biplot2\n  dev.off() # Close the PNG device  \n  \n  # Save the biplot of indviduals and variables a PNG file\n  png(\"bi_plot3.png\", width = 800, height = 600, units = \"px\", res = 100)\n  biplot3\n  dev.off() # Close the PNG device  "},{"path":"principal-component-analysis-pca.html","id":"pca-in-grapes","chapter":"3 Principal Component Analysis (PCA)","heading":"3.15 PCA in GRAPES","text":"csv file can uploaded GRAPES performing PCA. Read instructions carefully performing PCA GRAPES.","code":""},{"path":"references.html","id":"references","chapter":"4 References","heading":"4 References","text":"","code":""}]
