<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Cluster Analysis | MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH</title>
<meta name="author" content="Dr. PRATHEESH P GOPINATH">
<meta name="description" content="Cluster analysis, also known as clustering, is a data analysis technique used in statistics, machine learning, and data mining. It involves the process of grouping a set of objects or data points...">
<meta name="generator" content="bookdown 0.36 with bs4_book()">
<meta property="og:title" content="Chapter 5 Cluster Analysis | MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH">
<meta property="og:type" content="book">
<meta property="og:image" content="/images/cover.PNG">
<meta property="og:description" content="Cluster analysis, also known as clustering, is a data analysis technique used in statistics, machine learning, and data mining. It involves the process of grouping a set of objects or data points...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Cluster Analysis | MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH">
<meta name="twitter:description" content="Cluster analysis, also known as clustering, is a data analysis technique used in statistics, machine learning, and data mining. It involves the process of grouping a set of objects or data points...">
<meta name="twitter:image" content="/images/cover.PNG">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.29/datatables.js"></script><link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script><link href="libs/dt-ext-buttons-1.13.4/css/buttons.dataTables.min.css" rel="stylesheet">
<script src="libs/dt-ext-buttons-1.13.4/js/dataTables.buttons.min.js"></script><script src="libs/dt-ext-buttons-1.13.4/js/buttons.html5.min.js"></script><script src="libs/dt-ext-buttons-1.13.4/js/buttons.colVis.min.js"></script><script src="libs/dt-ext-buttons-1.13.4/js/buttons.print.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="r-and-r-studio.html"><span class="header-section-number">1</span> R and R studio</a></li>
<li><a class="" href="import.html"><span class="header-section-number">2</span> Importing data files in R</a></li>
<li><a class="" href="principal-component-analysis-pca.html"><span class="header-section-number">3</span> Principal Component Analysis (PCA)</a></li>
<li><a class="" href="exploratory-factor-analysis.html"><span class="header-section-number">4</span> Exploratory Factor Analysis</a></li>
<li><a class="active" href="cluster-analysis.html"><span class="header-section-number">5</span> Cluster Analysis</a></li>
<li><a class="" href="references.html"><span class="header-section-number">6</span> References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="cluster-analysis" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Cluster Analysis<a class="anchor" aria-label="anchor" href="#cluster-analysis"><i class="fas fa-link"></i></a>
</h1>
<p>Cluster analysis, also known as clustering, is a data analysis technique used in statistics, machine learning, and data mining. It involves the process of grouping a set of objects or data points into clusters or subsets, with the aim of organizing similar items together while keeping dissimilar items apart. The primary goal of cluster analysis is to identify patterns, structures, or natural groupings within a dataset.<span class="citation">(<a href="references.html#ref-hastie2009">Hastie, Tibshirani, and Friedman 2009</a>)</span><br>
Mainly two types of clustering is discussed in this section.</p>
<ul>
<li><p>Hierarchical clustering</p></li>
<li><p>K-means clustering</p></li>
</ul>
<p>We will be using <code>cluster</code>, <code>ggplot2</code>, <code>pheatmap</code> and <code>factominer</code> packages to do cluster analysis.</p>
<p><strong>Install the required packages</strong>:</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install two pacakges cluster and factominer</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cluster"</span>, <span class="st">"factominer"</span>,<span class="st">"ggplot2"</span>,<span class="st">"pheatmap"</span><span class="op">)</span><span class="op">)</span>  </span></code></pre></div>
<p>We will be using the “mtcars” dataset, which is a well-known dataset in R that contains information about various car models from the 1970s, specifically 1973 and 1974. It provides data on the characteristics of these cars, such as their miles per gallon (mpg), number of cylinders, horsepower, weight, and more.<br>
We will perform cluster analysis using this data.</p>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-9d90595213699435b169" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-9d90595213699435b169">{"x":{"filter":"none","vertical":false,"extensions":["Buttons"],"data":[["Mazda RX4","Mazda RX4 Wag","Datsun 710","Hornet 4 Drive","Hornet Sportabout","Valiant","Duster 360","Merc 240D","Merc 230","Merc 280","Merc 280C","Merc 450SE","Merc 450SL","Merc 450SLC","Cadillac Fleetwood","Lincoln Continental","Chrysler Imperial","Fiat 128","Honda Civic","Toyota Corolla","Toyota Corona","Dodge Challenger","AMC Javelin","Camaro Z28","Pontiac Firebird","Fiat X1-9","Porsche 914-2","Lotus Europa","Ford Pantera L","Ferrari Dino","Maserati Bora","Volvo 142E"],[21,21,22.8,21.4,18.7,18.1,14.3,24.4,22.8,19.2,17.8,16.4,17.3,15.2,10.4,10.4,14.7,32.4,30.4,33.9,21.5,15.5,15.2,13.3,19.2,27.3,26,30.4,15.8,19.7,15,21.4],[6,6,4,6,8,6,8,4,4,6,6,8,8,8,8,8,8,4,4,4,4,8,8,8,8,4,4,4,8,6,8,4],[160,160,108,258,360,225,360,146.7,140.8,167.6,167.6,275.8,275.8,275.8,472,460,440,78.7,75.7,71.09999999999999,120.1,318,304,350,400,79,120.3,95.09999999999999,351,145,301,121],[110,110,93,110,175,105,245,62,95,123,123,180,180,180,205,215,230,66,52,65,97,150,150,245,175,66,91,113,264,175,335,109],[3.9,3.9,3.85,3.08,3.15,2.76,3.21,3.69,3.92,3.92,3.92,3.07,3.07,3.07,2.93,3,3.23,4.08,4.93,4.22,3.7,2.76,3.15,3.73,3.08,4.08,4.43,3.77,4.22,3.62,3.54,4.11],[2.62,2.875,2.32,3.215,3.44,3.46,3.57,3.19,3.15,3.44,3.44,4.07,3.73,3.78,5.25,5.424,5.345,2.2,1.615,1.835,2.465,3.52,3.435,3.84,3.845,1.935,2.14,1.513,3.17,2.77,3.57,2.78],[16.46,17.02,18.61,19.44,17.02,20.22,15.84,20,22.9,18.3,18.9,17.4,17.6,18,17.98,17.82,17.42,19.47,18.52,19.9,20.01,16.87,17.3,15.41,17.05,18.9,16.7,16.9,14.5,15.5,14.6,18.6]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>mpg<\/th>\n      <th>cyl<\/th>\n      <th>disp<\/th>\n      <th>hp<\/th>\n      <th>drat<\/th>\n      <th>wt<\/th>\n      <th>qsec<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"Bfrtip","buttons":[{"extend":"csv","text":"Download CSV ⬇","filename":"data"}],"searching":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script><div id="dataset-import" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Dataset import<a class="anchor" aria-label="anchor" href="#dataset-import"><i class="fas fa-link"></i></a>
</h2>
<p>First prepare your data set similar to above and save it as a csv file. Then import the data set in to R. See chapter <a href="import.html#import">2</a>to know how to save a csv file and import it to R. Also you can directly use the code below to import dataset from your computer to R.</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"path to your file"</span>, row.names<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#your file will be saved in the name data</span></span></code></pre></div>
<p>Please note the path copied from your system will be in the format <code>C:\Users\HP\Documents\</code>, change it to this format <code>C:/Users/HP/Documents/</code> in R.</p>

<div class="rmdnote">
While importing csv file for Factor Analysis don’t forget to set first column as rownames. In the code above row.names = 1 will set the first column as rowname.
</div>
</div>
<div id="hierarchical-clustering" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Hierarchical clustering<a class="anchor" aria-label="anchor" href="#hierarchical-clustering"><i class="fas fa-link"></i></a>
</h2>
<p>It is an unsupervised clustering method that groups data points into clusters based on their similarities without using predefined labels or categories. It is often used for exploratory data analysis and visualization.<br>
Hierarchical clustering is used when you don’t have prior knowledge of the number of clusters or how data points should be grouped. It starts with each data point as its cluster and gradually merges them based on their similarities.</p>
<p>Hierarchical clustering is widely used in biology for gene expression analysis, in marketing for customer segmentation, and in various fields for taxonomy, where the objective is to discover the natural hierarchy of groupings in the data.</p>
<p>Two approaches are there:</p>
<div id="agglomerative-clustering" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Agglomerative clustering<a class="anchor" aria-label="anchor" href="#agglomerative-clustering"><i class="fas fa-link"></i></a>
</h3>
<p>In the agglomerative approach, data points start as individual clusters and are successively merged</p>
</div>
<div id="divisive-clustering" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Divisive clustering<a class="anchor" aria-label="anchor" href="#divisive-clustering"><i class="fas fa-link"></i></a>
</h3>
<p>In divisive all data points begin in a single cluster and are successively split into smaller clusters.</p>
</div>
<div id="dendrogram" class="section level3" number="5.2.3">
<h3>
<span class="header-section-number">5.2.3</span> Dendrogram<a class="anchor" aria-label="anchor" href="#dendrogram"><i class="fas fa-link"></i></a>
</h3>
<p>Hierarchical clustering produces a dendrogram, a tree-like diagram that illustrates the merging or splitting of clusters at different levels. This dendrogram helps visualize the hierarchy of clusters and can guide the selection of the optimal number of clusters.</p>
</div>
</div>
<div id="hierrachial-clustering-in-r" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Hierrachial clustering in R<a class="anchor" aria-label="anchor" href="#hierrachial-clustering-in-r"><i class="fas fa-link"></i></a>
</h2>
<div id="agglomerative-hierrarchial-clustering" class="section level3" number="5.3.1">
<h3>
<span class="header-section-number">5.3.1</span> Agglomerative hierrarchial clustering<a class="anchor" aria-label="anchor" href="#agglomerative-hierrarchial-clustering"><i class="fas fa-link"></i></a>
</h3>
<p>First step is to normalize the data, sometimes we have variables in different scales, need to normalized based on scale function before clustering the data sets.</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#import your csv and save it in the name "data" and use row names as first column.</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/scale.html">scale</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span></code></pre></div>
<p>R function <code><a href="https://rdrr.io/r/stats/hclust.html">hclust()</a></code> is used. It takes a dissimilarity matrix as an input, which is calculated using the function <code><a href="https://rdrr.io/r/stats/dist.html">dist()</a></code>.<br>
Compute the distance matrix and then use the hclust() function with appropriate linkage method.</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># perform agglomerative clustering with linkage method ward.D2</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://www.sthda.com/english/rpkgs/factoextra">"factoextra"</a></span><span class="op">)</span></span>
<span><span class="va">res.hc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>,  method <span class="op">=</span> <span class="st">"ward.D2"</span><span class="op">)</span></span>
<span><span class="co"># create dendrogram</span></span>
<span><span class="va">p</span><span class="op">&lt;-</span><span class="fu">factoextra</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">res.hc</span>, cex <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="co"># cex: label size  </span></span>
<span><span class="va">p</span></span></code></pre></div>
<div class="inline-figure"><img src="lecture_note_files/figure-html/dist_cl-1.png" width="672"></div>
</div>
<div id="linkage-methods" class="section level3" number="5.3.2">
<h3>
<span class="header-section-number">5.3.2</span> Linkage methods<a class="anchor" aria-label="anchor" href="#linkage-methods"><i class="fas fa-link"></i></a>
</h3>
<p>Several linkage methods are commonly used in hierarchical clustering. Here’s a brief summary of these methods:<br>
you can use any of these method inside the argument <code>method</code> in <code><a href="https://rdrr.io/r/stats/hclust.html">hclust()</a></code> function</p>
<p><strong>“ward.D” and “ward.D2”</strong>: Ward’s method minimizes the increase in the within-cluster sum of squares when merging clusters. “ward.D” uses the Euclidean distance, while “ward.D2” uses the squared Euclidean distance. These methods are often preferred when you want to create well-balanced clusters.</p>
<p><strong>“single”</strong>: Single linkage calculates the minimum pairwise distance between any two points in different clusters. It tends to create stringy, elongated clusters and can be sensitive to outliers.</p>
<p><strong>“complete”</strong>: Complete linkage calculates the maximum pairwise distance between points in different clusters. It produces more compact clusters and is less sensitive to outliers than single linkage.</p>
<p><strong>“average”</strong>: Average linkage computes the average distance between all pairs of data points from different clusters. It balances the trade-off between single and complete linkage and is a common choice for many applications.</p>
<p><strong>“mcquitty”</strong>: McQuitty linkage is a modification of complete linkage designed to address some of the issues associated with complete linkage. It is a weighted method that reduces the sensitivity to outliers.</p>
<p><strong>“median”</strong>: Median linkage calculates the distance between the medians of clusters. It can result in clusters of various shapes and sizes.</p>
<p><strong>“centroid”</strong>: Centroid linkage calculates the distance between the centroids of clusters. Similar to median linkage, it can lead to clusters of different shapes and sizes.</p>
<p>These linkage methods allow you to control how clusters are formed during the hierarchical clustering process. The choice of method depends on your specific data, objectives, and preferences for the characteristics of the resulting clusters. Experimenting with different methods and assessing their suitability for your particular dataset is often necessary to determine the most appropriate linkage method. In our example we have used <code>ward.D2</code>.</p>
</div>
<div id="customizing-dendrogram" class="section level3" number="5.3.3">
<h3>
<span class="header-section-number">5.3.3</span> Customizing dendrogram<a class="anchor" aria-label="anchor" href="#customizing-dendrogram"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose you decide with 7 clusters and want to colour it accordingly use this code:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">res.hc</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, k <span class="op">=</span> <span class="fl">7</span>, palette <span class="op">=</span> <span class="st">"jco"</span><span class="op">)</span> </span>
<span><span class="co"># 'k=' specifies the number of clusters</span></span>
<span><span class="va">p</span></span></code></pre></div>
<div class="inline-figure">
<img src="lecture_note_files/figure-html/col_dendro-1.png" width="672">
Suppose we want to draw rectangle around the required number of clusters. we have selected the number of clusters as 7</div>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p</span><span class="op">&lt;-</span><span class="fu">factoextra</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_dend.html">fviz_dend</a></span><span class="op">(</span><span class="va">res.hc</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, k<span class="op">=</span><span class="fl">7</span>, rect <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">p</span></span></code></pre></div>
<div class="inline-figure"><img src="lecture_note_files/figure-html/rectdend-1.png" width="672"></div>
<p>You can save the dendrogram using the code below:</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Save dendrogram</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsave.html">ggsave</a></span> <span class="op">(</span><span class="st">"dendro.png"</span>,plot <span class="op">=</span> <span class="va">p</span>,width<span class="op">=</span><span class="fl">6</span>, height <span class="op">=</span> <span class="fl">4</span>, dpi<span class="op">=</span><span class="fl">300</span><span class="op">)</span></span></code></pre></div>
<div id="heat-map" class="section level4" number="5.3.3.1">
<h4>
<span class="header-section-number">5.3.3.1</span> Heat Map<a class="anchor" aria-label="anchor" href="#heat-map"><i class="fas fa-link"></i></a>
</h4>
<p>A heatmap is another way to visualize hierarchical clustering. It’s also called a false colored image, where data values are transformed to color scale. Heat maps allow us to simultaneously visualize groups of samples and features. You can easily create a pretty heatmap using the R package <code>pheatmap</code>.</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">pheatmap</span><span class="op">)</span></span>
<span><span class="va">heatmap</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/pheatmap/man/pheatmap.html">pheatmap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, cutree_cols <span class="op">=</span> <span class="fl">7</span><span class="op">)</span>  </span>
<span><span class="va">heatmap</span></span></code></pre></div>
<div class="inline-figure"><img src="lecture_note_files/figure-html/heatmap-1.png" width="672"></div>
<p>You can save the heatmap using the code below:</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Save heat map</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsave.html">ggsave</a></span> <span class="op">(</span><span class="st">"heatmap.png"</span>,plot <span class="op">=</span> <span class="va">heatmap</span>,width<span class="op">=</span><span class="fl">6</span>, height <span class="op">=</span> <span class="fl">4</span>, dpi<span class="op">=</span><span class="fl">300</span><span class="op">)</span></span></code></pre></div>
<p>In heatmap, generally, columns are samples and rows are variables.</p>
</div>
<div id="silhouette-plot" class="section level4" number="5.3.3.2">
<h4>
<span class="header-section-number">5.3.3.2</span> silhouette plot<a class="anchor" aria-label="anchor" href="#silhouette-plot"><i class="fas fa-link"></i></a>
</h4>
<p>The silhouette score is a widely used metric for evaluating the quality of clusters in unsupervised machine learning. It provides a measure of how well-separated and distinct the clusters are, offering valuable insights into the effectiveness of a clustering algorithm. The silhouette score is calculated for each data point, assessing its similarity to the other data points within the same cluster compared to the nearest neighboring cluster. It ranges from -1 to 1, where a high silhouette score (close to 1) indicates that a data point is appropriately placed in its cluster, while a low score (close to -1) suggests that it might be more suited to a different cluster. A silhouette score close to zero implies that a data point is on or very close to the decision boundary between two clusters. This metric aids in selecting the optimal number of clusters and is a valuable tool for cluster validation and interpretation.<br>
In a silhouette plot the y-axis typically represents individual data points or samples and x-axis represents silhouette values. Each data point in the dataset is represented on the plot as a vertical bar. The height of the bar corresponds to the silhouette value of that data point.<br>
Silhouette plots are organized by clusters, with each cluster’s data points grouped together. This helps visualize the structure of individual clusters and their overall quality.</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Silhoutte plot  </span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/cluster/">cluster</a></span><span class="op">)</span></span>
<span><span class="va">distance</span> <span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/cluster/man/silhouette.html">silhouette</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span><span class="op">(</span><span class="va">res.hc</span>,<span class="fl">7</span><span class="op">)</span>, <span class="va">distance</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure">
<img src="lecture_note_files/figure-html/silhoutte-1.png" width="672">
In our example we have an average silhoutte width of 0.44, indicating that, on average, the data points are well-clustered and have a high degree of similarity to their respective clusters compared to neighboring clusters.</div>
</div>
</div>
<div id="divisive-hierrarchial-clustering" class="section level3" number="5.3.4">
<h3>
<span class="header-section-number">5.3.4</span> Divisive hierrarchial clustering<a class="anchor" aria-label="anchor" href="#divisive-hierrarchial-clustering"><i class="fas fa-link"></i></a>
</h3>
<p>Also known as DIvisive ANAlysis (DIANA) Clustering. In this lecture we will be limiting our discussion in Agglomerative clustering alone as divisive clustering not much widely used in agricultural research.</p>
</div>
</div>
<div id="k-means-clustering" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> K means clustering<a class="anchor" aria-label="anchor" href="#k-means-clustering"><i class="fas fa-link"></i></a>
</h2>
<p>K means clustering is another unsupervised clustering method that partitions data points into k clusters based on their similarities. It is widely used for grouping data when the number of clusters is known or can be estimated.</p>
<p>Unlike hierarchical clustering, k-means requires you to specify the number of clusters (k) in advance. It tries to find cluster centroids and assigns data points to the nearest centroid based on their features. K-means is a centroid-based algorithm, where the centroids represent the center of each cluster. Data points are assigned to the cluster whose centroid is closest to them.</p>
<p>K-means is used in image compression, customer segmentation, document clustering, and recommendation systems. It is a versatile method for grouping data when the number of clusters is known or can be estimated based on the problem domain.</p>
<p>In summary, hierarchical clustering is a method for discovering the natural hierarchy of clusters in data, and it can be applied in unsupervised scenarios where the number of clusters is not predetermined. On the other hand, k-means clustering is a centroid-based method used to partition data into a specified number of clusters, making it suitable for unsupervised clustering tasks with a known or estimated number of clusters.</p>
<div id="k-means-using-r" class="section level3" number="5.4.1">
<h3>
<span class="header-section-number">5.4.1</span> K means using R<a class="anchor" aria-label="anchor" href="#k-means-using-r"><i class="fas fa-link"></i></a>
</h3>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="exploratory-factor-analysis.html"><span class="header-section-number">4</span> Exploratory Factor Analysis</a></div>
<div class="next"><a href="references.html"><span class="header-section-number">6</span> References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#cluster-analysis"><span class="header-section-number">5</span> Cluster Analysis</a></li>
<li><a class="nav-link" href="#dataset-import"><span class="header-section-number">5.1</span> Dataset import</a></li>
<li>
<a class="nav-link" href="#hierarchical-clustering"><span class="header-section-number">5.2</span> Hierarchical clustering</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#agglomerative-clustering"><span class="header-section-number">5.2.1</span> Agglomerative clustering</a></li>
<li><a class="nav-link" href="#divisive-clustering"><span class="header-section-number">5.2.2</span> Divisive clustering</a></li>
<li><a class="nav-link" href="#dendrogram"><span class="header-section-number">5.2.3</span> Dendrogram</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#hierrachial-clustering-in-r"><span class="header-section-number">5.3</span> Hierrachial clustering in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#agglomerative-hierrarchial-clustering"><span class="header-section-number">5.3.1</span> Agglomerative hierrarchial clustering</a></li>
<li><a class="nav-link" href="#linkage-methods"><span class="header-section-number">5.3.2</span> Linkage methods</a></li>
<li><a class="nav-link" href="#customizing-dendrogram"><span class="header-section-number">5.3.3</span> Customizing dendrogram</a></li>
<li><a class="nav-link" href="#divisive-hierrarchial-clustering"><span class="header-section-number">5.3.4</span> Divisive hierrarchial clustering</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#k-means-clustering"><span class="header-section-number">5.4</span> K means clustering</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#k-means-using-r"><span class="header-section-number">5.4.1</span> K means using R</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH</strong>" was written by Dr. PRATHEESH P GOPINATH. It was last built on 2023-10-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
