<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 3 Principal Component Analysis | MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH</title>
<meta name="author" content="Dr. PRATHEESH P GOPINATH">
<meta name="description" content="3.1 What is PCA? Principal component analysis (PCA) is a technique that transforms high-dimensions data into lower-dimensions while retaining as much information as possible. Drawing meaningful...">
<meta name="generator" content="bookdown 0.36 with bs4_book()">
<meta property="og:title" content="Chapter 3 Principal Component Analysis | MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH">
<meta property="og:type" content="book">
<meta property="og:image" content="/images/cover.PNG">
<meta property="og:description" content="3.1 What is PCA? Principal component analysis (PCA) is a technique that transforms high-dimensions data into lower-dimensions while retaining as much information as possible. Drawing meaningful...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3 Principal Component Analysis | MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH">
<meta name="twitter:description" content="3.1 What is PCA? Principal component analysis (PCA) is a technique that transforms high-dimensions data into lower-dimensions while retaining as much information as possible. Drawing meaningful...">
<meta name="twitter:image" content="/images/cover.PNG">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.29/datatables.js"></script><link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script><link href="libs/dt-ext-buttons-1.13.4/css/buttons.dataTables.min.css" rel="stylesheet">
<script src="libs/dt-ext-buttons-1.13.4/js/dataTables.buttons.min.js"></script><script src="libs/dt-ext-buttons-1.13.4/js/buttons.html5.min.js"></script><script src="libs/dt-ext-buttons-1.13.4/js/buttons.colVis.min.js"></script><script src="libs/dt-ext-buttons-1.13.4/js/buttons.print.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled"><li><a class="" href="index.html"><span class="header-section-number">Chapter 3</span> Principal Component Analysis</a></li></ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="principal-component-analysis" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> Principal Component Analysis<a class="anchor" aria-label="anchor" href="#principal-component-analysis"><i class="fas fa-link"></i></a>
</h1>
<div id="what-is-pca" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> What is PCA?<a class="anchor" aria-label="anchor" href="#what-is-pca"><i class="fas fa-link"></i></a>
</h2>
<p>Principal component analysis (PCA) is a technique that transforms high-dimensions data into lower-dimensions while retaining as much information as possible.</p>
<p>Drawing meaningful inferences from high-dimensional data can be challenging, as humans naturally excel at visualizing and comprehending information in two dimensions. PCA, a powerful technique, aids in transforming multi-dimensional data into a more manageable form by reducing its dimensionality. This simplification facilitates easier visualization and analysis, ultimately enhancing our ability to extract valuable insights from complex datasets.</p>
<p>PCA is a valuable tool in social science and agricultural research. It works by transforming multi-dimensional data into a lower-dimensional space while retaining as much variance in the data as possible. In essence, PCA identifies the most significant dimensions or “principal components” of the data, effectively reducing its complexity.
The idea of PCA is simple — reduce the number of variables of a data set, while preserving as much information as possible.</p>
</div>
<div id="when-to-use-pca" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> When to Use PCA<a class="anchor" aria-label="anchor" href="#when-to-use-pca"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Dimensionality Reduction</strong>: Use PCA when you have a high-dimensional dataset with many features (variables) and you want to reduce its dimensionality. This can help in cases where you have too many variables to work with efficiently.</p>
<p><strong>Data Visualization</strong>: PCA is effective when you need to visualize high-dimensional data. By projecting data onto a lower-dimensional space, you can create scatter plots, heatmaps, or other visualizations that are easier to interpret.</p>
<p><strong>Minimum data set</strong>: Principal components can be used to eliminate some data sets and identify a minimum data set for further experimentation.</p>
<p><strong>Noise Reduction</strong>: If your dataset contains noisy or redundant features, PCA can help by capturing the most important information and eliminating the less relevant components.</p>
<p><strong>Multicollinearity</strong>: When your dataset has multicollinearity issues (high correlations between variables), PCA can help reduce these interdependencies, making models more stable and interpretable.</p>
<p>Sample size (n) should be at least equal to number of dimensions (n ≥ p)</p>
</div>
<div id="when-not-to-use-pca" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> When Not to Use PCA<a class="anchor" aria-label="anchor" href="#when-not-to-use-pca"><i class="fas fa-link"></i></a>
</h2>
<p>When the <strong>sample size</strong> is less than number of dimensions (n &lt; p)</p>
<p><strong>Non-Linear Relationships</strong>: PCA is based on linear transformations and may not be effective when your data contains complex non-linear relationships. In such cases, techniques like kernel PCA or other non-linear dimensionality reduction methods might be more appropriate.</p>
<p><strong>Small Dimensionality</strong>: If you already have a low-dimensional dataset with only a few important variables, applying PCA might not provide significant benefits and could even lead to information loss.</p>
<p><strong>Loss of Variability Information</strong>: PCA aims to maximize variance capture, which may not be desirable in some cases. If preserving other characteristics of the data is more important (e.g., categorical information), other dimensionality reduction techniques should be considered.</p>
</div>
<div id="how-pca-is-done" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> How PCA is done<a class="anchor" aria-label="anchor" href="#how-pca-is-done"><i class="fas fa-link"></i></a>
</h2>
<p>In this training program, we are primarily focused on the practical application of PCA rather than delving into its theoretical aspects. Our aim is to explore when and how PCA can be effectively utilized and to understand how to interpret the results in a meaningful manner.</p>
<p>-Standardize the range of continuous initial variables<br>
-Compute the covariance matrix to identify correlations<br>
-Compute the eigen vectors and eigen values of the covariance matrix to identify the principal components<br>
-Create a feature vector to decide which principal components to keep -Recast the data along the principal components axes</p>
</div>
<div id="what-is-principal-component" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> What is Principal Component<a class="anchor" aria-label="anchor" href="#what-is-principal-component"><i class="fas fa-link"></i></a>
</h2>
<p>Principal components are new variables that are constructed as linear combinations of the initial variables. These combinations are done in such a way that the new variables (i.e. principal components) are uncorrelated and most of the information within the initial variables are included in the first components. So, the idea if 10-dimensional data gives you 10 principal components, but PCA tries to put maximum possible information in the first component, then maximum remaining information in the second and so on. In the scree plot below you can see 5 principal components of a 5-dimensional data and the corresponding variance explained.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pcavar"></span>
<img src="images/pcavar.png" alt="Scree Plot: Principal components and percentage variance explained" width="70%"><p class="caption">
Figure 3.1: Scree Plot: Principal components and percentage variance explained
</p>
</div>
</div>
<div id="how-pca-constructs-the-principal-components" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> How PCA Constructs the Principal Components<a class="anchor" aria-label="anchor" href="#how-pca-constructs-the-principal-components"><i class="fas fa-link"></i></a>
</h2>
Number of principal components are equal to the number of variables in the data, principal components are constructed in such a manner that the first principal component accounts for the largest possible variance in the data set. For example, see the Figure 1.2 below, we can see the scatter plot of our assumed data set, can we guess the first principal component ? Yes, it’s approximately the line that matches the purple marks because it goes through the origin and it’s the line in which the projection of the points (red dots) is the most spread out. Or mathematically speaking, it’s the line that maximizes the variance (the average of the squared distances from the projected points (red dots) to the origin).<br><div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pcagif"></span>
<img src="images/pca.gif" alt="Concept of PCA" width="100%"><p class="caption">
Figure 3.2: Concept of PCA
</p>
</div>
<p>These lines (PCs) were identified using linear algebra concepts Eigen vectors and eigen values which are calculated from the covariance matrix in order to determine the principal components of the data. We are not going much in to theoretical details.</p>
</div>
<div id="practical-example" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> PRACTICAL EXAMPLE<a class="anchor" aria-label="anchor" href="#practical-example"><i class="fas fa-link"></i></a>
</h2>
<p>We will be using Usarrests dataset in R to explain PCA in the coming sessions.The “USarrests” dataset in R is a built-in dataset that offers insights into crime and arrests across the 50 states of the United States in 1973. It comprises four key variables: murder rate, assault rate, the percentage of the population living in urban areas, and the rape rate.</p>
<p>You can View and download the datasets here</p>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-bd364768c4441ba88d10" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-bd364768c4441ba88d10">{"x":{"filter":"none","vertical":false,"extensions":["Buttons"],"data":[["Alabama","Alaska","Arizona","Arkansas","California","Colorado","Connecticut","Delaware","Florida","Georgia","Hawaii","Idaho","Illinois","Indiana","Iowa","Kansas","Kentucky","Louisiana","Maine","Maryland","Massachusetts","Michigan","Minnesota","Mississippi","Missouri","Montana","Nebraska","Nevada","New Hampshire","New Jersey","New Mexico","New York","North Carolina","North Dakota","Ohio","Oklahoma","Oregon","Pennsylvania","Rhode Island","South Carolina","South Dakota","Tennessee","Texas","Utah","Vermont","Virginia","Washington","West Virginia","Wisconsin","Wyoming"],[13.2,10,8.1,8.800000000000001,9,7.9,3.3,5.9,15.4,17.4,5.3,2.6,10.4,7.2,2.2,6,9.699999999999999,15.4,2.1,11.3,4.4,12.1,2.7,16.1,9,6,4.3,12.2,2.1,7.4,11.4,11.1,13,0.8,7.3,6.6,4.9,6.3,3.4,14.4,3.8,13.2,12.7,3.2,2.2,8.5,4,5.7,2.6,6.8],[236,263,294,190,276,204,110,238,335,211,46,120,249,113,56,115,109,249,83,300,149,255,72,259,178,109,102,252,57,159,285,254,337,45,120,151,159,106,174,279,86,188,201,120,48,156,145,81,53,161],[58,48,80,50,91,78,77,72,80,60,83,54,83,65,57,66,52,66,51,67,85,74,66,44,70,53,62,81,56,89,70,86,45,44,75,68,67,72,87,48,45,59,80,80,32,63,73,39,66,60],[21.2,44.5,31,19.5,40.6,38.7,11.1,15.8,31.9,25.8,20.2,14.2,24,21,11.3,18,16.3,22.2,7.8,27.8,16.3,35.1,14.9,17.1,28.2,16.4,16.5,46,9.5,18.8,32.1,26.1,16.1,7.3,21.4,20,29.3,14.9,8.300000000000001,22.5,12.8,26.9,25.5,22.9,11.2,20.7,26.2,9.300000000000001,10.8,15.6]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Murder<\/th>\n      <th>Assault<\/th>\n      <th>UrbanPop<\/th>\n      <th>Rape<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"Bfrtip","buttons":[{"extend":"csv","filename":"data"}],"searching":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="analysis" class="section level2" number="3.8">
<h2>
<span class="header-section-number">3.8</span> Analysis<a class="anchor" aria-label="anchor" href="#analysis"><i class="fas fa-link"></i></a>
</h2>
<p>First prepare your data set and save it as a csv file. Then import the data set in to R. See chapter <a href="import.html#import">2</a> to see how to save a csv file and import it to R. You can directly use the code to download dataset.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"path to your file"</span>, row.names<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>When you copy a path from your system to data please note that it will appear as “C:" which need to be changed as”C:/Users/HP/Documents/” in your code</p>

<div class="rmdnote">
While importing csv file for PCA don’t forget to set first column as rownames. In the code above row.names = 1 will set the first column as rowname.
</div>
<p>We will be using two packages for performing the analysis <code>factoextra</code>.<br><strong>Install the packages</strong>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"factoextra"</span><span class="op">)</span>  </span></code></pre></div>
<p><strong>Follow below codes for PCA analysis</strong></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sthda.com/english/rpkgs/factoextra">factoextra</a></span><span class="op">)</span></span>
<span><span class="co">#storing your dataset to the variable data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"csv/usarrests.csv"</span>, row.names<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#this will display the first 6 rows of your data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">data</span>, n <span class="op">=</span> <span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<pre><code>##            Murder Assault UrbanPop Rape
## Alabama      13.2     236       58 21.2
## Alaska       10.0     263       48 44.5
## Arizona       8.1     294       80 31.0
## Arkansas      8.8     190       50 19.5
## California    9.0     276       91 40.6
## Colorado      7.9     204       78 38.7</code></pre>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Do PCA using prcomp function in factoextra</span></span>
<span><span class="va">res.pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/prcomp.html">prcomp</a></span><span class="op">(</span><span class="va">data</span>, scale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>We will first visualize the results based on PCA and understand the concept then move to the analysis results.</p>
</div>
<div id="scree-plot" class="section level2" number="3.9">
<h2>
<span class="header-section-number">3.9</span> Scree Plot<a class="anchor" aria-label="anchor" href="#scree-plot"><i class="fas fa-link"></i></a>
</h2>
<p>A scree plot helps you decide how many principal components to retain in your PCA analysis. The choice of the number of components can vary depending on your specific goals, but it’s often based on a combination of statistical criteria, such as the explained variance and the elbow point, as well as domain knowledge and interpretability.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Visualize eigenvalues (scree plot)</span></span>
<span><span class="va">plot1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/eigenvalue.html">fviz_eig</a></span><span class="op">(</span><span class="va">res.pca</span>,addlabels <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">plot1</span></span></code></pre></div>
<p><img src="lecture_note_files/figure-html/PCA-anal1-1.png" width="672"><strong>Here are the key inferences you can make from this plot:</strong></p>
<p><strong>Explained Variance:</strong> The scree plot displays the proportion of total variance explained by each principal component. Inferences can be made by examining how much variance is explained by each component. The components on the left contribute the most to the variance, while those on the right contribute less.</p>
<p><strong>Elbow Point:</strong> Look for an “elbow” or point where the explained variance sharply decreases. This is often a good indicator of the number of principal components to retain. The point just before the explained variance starts to level off can be a suitable choice. It’s the point where adding more components doesn’t explain much additional variance.</p>
<p><strong>Cumulative Variance:</strong> You can also examine the cumulative explained variance. The scree plot may show a cumulative curve that increases as more components are added. You can look for the point where the cumulative variance reaches a satisfactory level (e.g., 70%, 80%, 90%) to determine the number of components to retain.</p>
<p><strong>Interpretability:</strong> Consider the interpretability of the components. Sometimes, you might choose to retain more components even if they explain less variance because they have meaningful interpretations in your context.</p>
<p><strong>Domain Knowledge:</strong> Always consider the domain or subject matter knowledge when deciding on the number of components to retain. Sometimes, the context of your analysis may dictate the number of components that are practically meaningful.</p>
</div>
<div id="biplot-indviduals" class="section level2" number="3.10">
<h2>
<span class="header-section-number">3.10</span> Biplot (Indviduals)<a class="anchor" aria-label="anchor" href="#biplot-indviduals"><i class="fas fa-link"></i></a>
</h2>
<p>A “Biplot of Individuals” is a graphical representation used in Principal Component Analysis (PCA) and other multivariate statistical methods to visualize how individual data points or observations are related to the underlying patterns and variables in a dataset. By examining the biplot, analysts and researchers can gain insights into various aspects of the data, including clustering patterns among individual observations.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Graph of individuals. Individuals with a similar profile are grouped together (Biplot)</span></span>
<span><span class="va">biplot1</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_pca.html">fviz_pca_ind</a></span><span class="op">(</span><span class="va">res.pca</span>,</span>
<span>             col.ind <span class="op">=</span> <span class="st">"cos2"</span>, <span class="co"># Color by the quality of representation</span></span>
<span>             gradient.cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"#00AFBB"</span>, <span class="st">"#E7B800"</span>, <span class="st">"#FC4E07"</span><span class="op">)</span>,</span>
<span>             repel <span class="op">=</span> <span class="cn">TRUE</span>     <span class="co"># Avoid text overlapping</span></span>
<span>             <span class="op">)</span></span>
<span><span class="va">biplot1</span></span></code></pre></div>
<p><img src="lecture_note_files/figure-html/PCA-anal2-1.png" width="672"><strong>Interpretation of the Biplot of indviduals</strong></p>
<p><strong>Individuals’ Position:</strong> Each point in the biplot represents an individual observation from your dataset. The positions of the points in the plot show how each individual relates to the principal components. Individuals closer to each other on the plot are more similar in terms of their relationships with the principal components.</p>
<p><strong>Color Coding:</strong> The points representing individuals may be color-coded based on the “cos2” values, which indicate the quality of representation of each individual on the plot. Higher “cos2” values indicate that an individual’s position on the plot is more strongly associated with the principal components.</p>
<p><strong>“cos2” in the Biplot:</strong><br>
In the context of a PCA biplot, “cos2” represents the square of the cosine of the angle between the individual’s position (point) and the variable’s arrow on the plot. It quantifies the quality of representation of an individual in the plot.</p>
<ul>
<li><p>High “cos2” values suggest that the individual’s position in the plot is well-represented by the variables and principal components.</p></li>
<li><p>Low “cos2” values suggest that the individual’s position may not be well-represented or may be noisy in the plot</p></li>
</ul>
</div>
<div id="biplot-variables" class="section level2" number="3.11">
<h2>
<span class="header-section-number">3.11</span> Biplot (variables)<a class="anchor" aria-label="anchor" href="#biplot-variables"><i class="fas fa-link"></i></a>
</h2>
<p>In this biplot, variables are represented as arrows or vectors, and the plot allows for the examination of how these variables are associated with each other and with the principal components.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Graph of variables. </span></span>
<span><span class="va">biplot2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_pca.html">fviz_pca_var</a></span><span class="op">(</span><span class="va">res.pca</span>,</span>
<span>             col.var <span class="op">=</span> <span class="st">"contrib"</span>, <span class="co"># Color by contributions to the PC</span></span>
<span>             gradient.cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"#00AFBB"</span>, <span class="st">"#E7B800"</span>, <span class="st">"#FC4E07"</span><span class="op">)</span>,</span>
<span>             repel <span class="op">=</span> <span class="cn">TRUE</span>     <span class="co"># Avoid text overlapping</span></span>
<span>             <span class="op">)</span></span>
<span><span class="va">biplot2</span></span></code></pre></div>
<p><img src="lecture_note_files/figure-html/PCA-anal3-1.png" width="672"><strong>Interpretation of the PCA Variable BiPlot:</strong></p>
<p><strong>Variable Positions:</strong> Each point in the variable plot represents a variable from your dataset. The positions of the points in the plot show how each variable relates to the principal components. Variables closer to each other on the plot are more similar in terms of their relationships with the principal components.</p>
<p><strong>Direction of Arrows:</strong> Arrows in the variable plot represent the variables and their contribution to the principal components. The direction of the arrows indicates how each variable is associated with each principal component. Variables pointing in the same direction are positively correlated with the corresponding component, while those pointing in opposite directions are negatively correlated. This helps you understand which variables move in the same direction as the component and which move in the opposite direction.</p>
<p><strong>Arrow Length:</strong> The length of the arrows indicates the strength of the relationship between variables and principal components. Longer arrows represent variables with a higher contribution to the component.</p>
<p><strong>Color Coding:</strong> The points representing variables may be color-coded based on their contributions to the principal components. Higher contributions are typically associated with a darker color.</p>
</div>
<div id="biplot-indviduals-and-variables" class="section level2" number="3.12">
<h2>
<span class="header-section-number">3.12</span> Biplot (Indviduals and variables)<a class="anchor" aria-label="anchor" href="#biplot-indviduals-and-variables"><i class="fas fa-link"></i></a>
</h2>
<p>This biplot combines individual data points represented as points in the plot with variables represented as arrows or vectors. It provides a powerful way to assess the relationships between individual observations and variables, offering insights into patterns, clusters, and associations within the data. By examining the positions of individuals and the directions of variable vectors, analysts can gain a holistic understanding of the data’s underlying structure, making it a valuable tool for dimensionality reduction and data exploration.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Biplot of individuals and variables</span></span>
<span><span class="va">biplot3</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/fviz_pca.html">fviz_pca_biplot</a></span><span class="op">(</span><span class="va">res.pca</span>, repel <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                col.var <span class="op">=</span> <span class="st">"#2E9FDF"</span>, <span class="co"># Variables color</span></span>
<span>                col.ind <span class="op">=</span> <span class="st">"#696969"</span>  <span class="co"># Individuals color</span></span>
<span>                <span class="op">)</span></span>
<span><span class="va">biplot3</span></span></code></pre></div>
<p><img src="lecture_note_files/figure-html/PCA-anal4-1.png" width="672"><strong>Interpretation of the PCA BiPlot (Individuals and Variables):</strong></p>
<p><strong>Distance from the Origin (Center):</strong> The distance of an individual point from the origin (center) of the plot represents its contribution to the explained variance by the principal components. Points that are further from the origin have a stronger influence on the principal components, while points closer to the origin have a weaker influence. In other words, individuals further from the origin are better represented by the principal components.</p>
<p><strong>Projection onto Arrows:</strong> The position of an individual point relative to the arrows tells you how that individual is influenced by the variables. If an individual point is projected close to the tip of an arrow, it indicates that this individual’s profile is strongly influenced by that particular variable represented by the arrow.</p>
<p><strong>Alignment of Points and Arrows:</strong> When the direction of arrows and the position of individuals align, it suggests that variables and individuals are positively correlated with the corresponding principal component. In other words, the variables that point in the same direction as the individual points contribute positively to the principal component.</p>
<p><strong>Opposite Direction:</strong> If an individual point and an arrow are in opposite directions, it indicates a negative correlation between the individual and the variable, implying that the variable contributes negatively to the principal component for that individual.</p>
<p>In summary, the relationship between the position of individuals and the direction of arrows in a PCA biplot provides insights into how individual observations relate to the variables and the principal components. The biplot helps you understand the strength and direction of these relationships, allowing you to identify which variables influence which components and how individuals are affected by these variables.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Save the scree plot as a PNG file</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/png.html">png</a></span><span class="op">(</span><span class="st">"eigenvalues_plot.png"</span>, width <span class="op">=</span> <span class="fl">800</span>, height <span class="op">=</span> <span class="fl">600</span>, units <span class="op">=</span> <span class="st">"px"</span>, res <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span>  <span class="va">plot1</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/dev.html">dev.off</a></span><span class="op">(</span><span class="op">)</span> <span class="co"># Close the PNG device  </span></span>
<span></span>
<span>  <span class="co"># Save the biplot of indviduals a PNG file</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/png.html">png</a></span><span class="op">(</span><span class="st">"bi_plot.png"</span>, width <span class="op">=</span> <span class="fl">800</span>, height <span class="op">=</span> <span class="fl">600</span>, units <span class="op">=</span> <span class="st">"px"</span>, res <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span>  <span class="va">biplot1</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/dev.html">dev.off</a></span><span class="op">(</span><span class="op">)</span> <span class="co"># Close the PNG device  </span></span>
<span>  </span>
<span>  <span class="co"># Save the biplot of variables a PNG file</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/png.html">png</a></span><span class="op">(</span><span class="st">"bi_plot2.png"</span>, width <span class="op">=</span> <span class="fl">800</span>, height <span class="op">=</span> <span class="fl">600</span>, units <span class="op">=</span> <span class="st">"px"</span>, res <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span>  <span class="va">biplot2</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/dev.html">dev.off</a></span><span class="op">(</span><span class="op">)</span> <span class="co"># Close the PNG device  </span></span>
<span>  </span>
<span>  <span class="co"># Save the biplot of indviduals and variables a PNG file</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/png.html">png</a></span><span class="op">(</span><span class="st">"bi_plot3.png"</span>, width <span class="op">=</span> <span class="fl">800</span>, height <span class="op">=</span> <span class="fl">600</span>, units <span class="op">=</span> <span class="st">"px"</span>, res <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span>  <span class="va">biplot3</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/grDevices/dev.html">dev.off</a></span><span class="op">(</span><span class="op">)</span> <span class="co"># Close the PNG device  </span></span></code></pre></div>
</div>
<div id="accessing-the-pca-results" class="section level2" number="3.13">
<h2>
<span class="header-section-number">3.13</span> Accessing the PCA results<a class="anchor" aria-label="anchor" href="#accessing-the-pca-results"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Eigenvalues</span></span>
<span><span class="va">eig.val</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/eigenvalue.html">get_eigenvalue</a></span><span class="op">(</span><span class="va">res.pca</span><span class="op">)</span></span>
<span><span class="va">eig.val</span></span></code></pre></div>
<pre><code>##       eigenvalue variance.percent cumulative.variance.percent
## Dim.1  2.4802416        62.006039                    62.00604
## Dim.2  0.9897652        24.744129                    86.75017
## Dim.3  0.3565632         8.914080                    95.66425
## Dim.4  0.1734301         4.335752                   100.00000</code></pre>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Results for Variables</span></span>
<span><span class="va">res.var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/get_pca.html">get_pca_var</a></span><span class="op">(</span><span class="va">res.pca</span><span class="op">)</span></span>
<span><span class="va">res.var</span><span class="op">$</span><span class="va">coord</span>          <span class="co"># Coordinates  </span></span></code></pre></div>
<pre><code>##               Dim.1      Dim.2      Dim.3       Dim.4
## Murder   -0.8439764 -0.4160354  0.2037600  0.27037052
## Assault  -0.9184432 -0.1870211  0.1601192 -0.30959159
## UrbanPop -0.4381168  0.8683282  0.2257242  0.05575330
## Rape     -0.8558394  0.1664602 -0.4883190  0.03707412</code></pre>
<p>The provided coordinates (Dim.1 (PC1) and Dim.2 (PC2)) for the variables (Murder, Assault, UrbanPop, and Rape) in a Principal Component Analysis (PCA) represent how these variables are positioned in the two-dimensional space defined by the first and second principal components (PC1 and PC2). Here’s what we can infer based on these coordinates:<br>
In PC1 (Dim.1), all the variables have negative coordinates, suggesting that they are inversely related to this principal component, i.e those states with high values in this PC will have lower crime rate. Variables with larger absolute values in Dim.1 (i.e., Murder, Assault, and Rape) have a stronger influence on PC1. This means that these variables are negatively correlated with PC1; as their values increase, PC1 decreases. UrbanPop has a smaller absolute value in Dim.1, indicating a weaker influence on PC1.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res.var</span><span class="op">$</span><span class="va">contrib</span>        <span class="co"># Contributions to the PCs</span></span></code></pre></div>
<pre><code>##              Dim.1     Dim.2     Dim.3     Dim.4
## Murder   28.718825 17.487524 11.643977 42.149674
## Assault  34.010315  3.533859  7.190358 55.265468
## UrbanPop  7.739016 76.179065 14.289594  1.792325
## Rape     29.531844  2.799553 66.876071  0.792533</code></pre>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res.var</span><span class="op">$</span><span class="va">cos2</span>           <span class="co"># Quality of representation </span></span></code></pre></div>
<pre><code>##              Dim.1     Dim.2      Dim.3       Dim.4
## Murder   0.7122962 0.1730854 0.04151814 0.073100217
## Assault  0.8435380 0.0349769 0.02563817 0.095846950
## UrbanPop 0.1919463 0.7539938 0.05095143 0.003108430
## Rape     0.7324611 0.0277090 0.23845544 0.001374491</code></pre>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Results for individuals</span></span>
<span><span class="va">res.ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/factoextra/man/get_pca.html">get_pca_ind</a></span><span class="op">(</span><span class="va">res.pca</span><span class="op">)</span></span>
<span><span class="va">res.ind</span><span class="op">$</span><span class="va">coord</span>          <span class="co"># Coordinates</span></span></code></pre></div>
<pre><code>##                      Dim.1       Dim.2       Dim.3        Dim.4
## Alabama        -0.97566045 -1.12200121  0.43980366  0.154696581
## Alaska         -1.93053788 -1.06242692 -2.01950027 -0.434175454
## Arizona        -1.74544285  0.73845954 -0.05423025 -0.826264240
## Arkansas        0.13999894 -1.10854226 -0.11342217 -0.180973554
## California     -2.49861285  1.52742672 -0.59254100 -0.338559240
## Colorado       -1.49934074  0.97762966 -1.08400162  0.001450164
## Connecticut     1.34499236  1.07798362  0.63679250 -0.117278736
## Delaware       -0.04722981  0.32208890  0.71141032 -0.873113315
## Florida        -2.98275967 -0.03883425  0.57103206 -0.095317042
## Georgia        -1.62280742 -1.26608838  0.33901818  1.065974459
## Hawaii          0.90348448  1.55467609 -0.05027151  0.893733198
## Idaho           1.62331903 -0.20885253 -0.25719021 -0.494087852
## Illinois       -1.36505197  0.67498834  0.67068647 -0.120794916
## Indiana         0.50038122  0.15003926 -0.22576277  0.420397595
## Iowa            2.23099579  0.10300828 -0.16291036  0.017379470
## Kansas          0.78887206  0.26744941 -0.02529648  0.204421034
## Kentucky        0.74331256 -0.94880748  0.02808429  0.663817237
## Louisiana      -1.54909076 -0.86230011  0.77560598  0.450157791
## Maine           2.37274014 -0.37260865  0.06502225 -0.327138529
## Maryland       -1.74564663 -0.42335704  0.15566968 -0.553450589
## Massachusetts   0.48128007  1.45967706  0.60337172 -0.177793902
## Michigan       -2.08725025  0.15383500 -0.38100046  0.101343128
## Minnesota       1.67566951  0.62590670 -0.15153200  0.066640316
## Mississippi    -0.98647919 -2.36973712  0.73336290  0.213342049
## Missouri       -0.68978426  0.26070794 -0.37365033  0.223554811
## Montana         1.17353751 -0.53147851 -0.24440796  0.122498555
## Nebraska        1.25291625  0.19200440 -0.17380930  0.015733156
## Nevada         -2.84550542  0.76780502 -1.15168793  0.311354436
## New Hampshire   2.35995585  0.01790055 -0.03648498 -0.032804291
## New Jersey     -0.17974128  1.43493745  0.75677041  0.240936580
## New Mexico     -1.96012351 -0.14141308 -0.18184598 -0.336121113
## New York       -1.66566662  0.81491072  0.63661186 -0.013348844
## North Carolina -1.11208808 -2.20561081  0.85489245 -0.944789648
## North Dakota    2.96215223 -0.59309738 -0.29824930 -0.251434626
## Ohio            0.22369436  0.73477837  0.03082616  0.469152817
## Oklahoma        0.30864928  0.28496113  0.01515592  0.010228476
## Oregon         -0.05852787  0.53596999 -0.93038718 -0.235390872
## Pennsylvania    0.87948680  0.56536050  0.39660218  0.355452378
## Rhode Island    0.85509072  1.47698328  1.35617705 -0.607402746
## South Carolina -1.30744986 -1.91397297  0.29751723 -0.130145378
## South Dakota    1.96779669 -0.81506822 -0.38538073 -0.108470512
## Tennessee      -0.98969377 -0.85160534 -0.18619262  0.646302674
## Texas          -1.34151838  0.40833518  0.48712332  0.636731051
## Utah            0.54503180  1.45671524 -0.29077592 -0.081486749
## Vermont         2.77325613 -1.38819435 -0.83280797 -0.143433697
## Virginia        0.09536670 -0.19772785 -0.01159482  0.209246429
## Washington      0.21472339  0.96037394 -0.61859067 -0.218628161
## West Virginia   2.08739306 -1.41052627 -0.10372163  0.130583080
## Wisconsin       2.05881199  0.60512507  0.13746933  0.182253407
## Wyoming         0.62310061 -0.31778662  0.23824049 -0.164976866</code></pre>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res.ind</span><span class="op">$</span><span class="va">contrib</span>        <span class="co"># Contributions to the PCs</span></span></code></pre></div>
<pre><code>##                      Dim.1        Dim.2        Dim.3        Dim.4
## Alabama        0.767597252 2.543809e+00 1.084954e+00 2.759732e-01
## Alaska         3.005333458 2.280846e+00 2.287607e+01 2.173883e+00
## Arizona        2.456672592 1.101923e+00 1.649593e-02 7.873058e+00
## Arkansas       0.015804674 2.483147e+00 7.215881e-02 3.776903e-01
## California     5.034240388 4.714315e+00 1.969384e+00 1.321828e+00
## Colorado       1.812744908 1.931286e+00 6.591031e+00 2.425157e-05
## Connecticut    1.458732469 2.348130e+00 2.274518e+00 1.586149e-01
## Delaware       0.001798740 2.096280e-01 2.838794e+00 8.791172e+00
## Florida        7.174184420 3.047387e-03 1.829003e+00 1.047723e-01
## Georgia        2.123586621 3.239111e+00 6.446730e-01 1.310386e+01
## Hawaii         0.658229595 4.884023e+00 1.417547e-02 9.211309e+00
## Idaho          2.124925819 8.814087e-02 3.710243e-01 2.815230e+00
## Illinois       1.502568867 9.206411e-01 2.523089e+00 1.682685e-01
## Indiana        0.201900787 4.548913e-02 2.858895e-01 2.038102e+00
## Iowa           4.013594673 2.144085e-02 1.488644e-01 3.483202e-03
## Kansas         0.501821384 1.445377e-01 3.589333e-03 4.818998e-01
## Kentucky       0.445532054 1.819089e+00 4.424054e-03 5.081625e+00
## Louisiana      1.935039081 1.502501e+00 3.374239e+00 2.336873e+00
## Maine          4.539796293 2.805458e-01 2.371469e-02 1.234153e+00
## Maryland       2.457246257 3.621691e-01 1.359257e-01 3.532346e+00
## Massachusetts  0.186780601 4.305379e+00 2.042036e+00 3.645350e-01
## Michigan       3.513055856 4.781984e-02 8.142251e-01 1.184388e-01
## Minnesota      2.264189355 7.916205e-01 1.287959e-01 5.121293e-02
## Mississippi    0.784714837 1.134745e+01 3.016695e+00 5.248781e-01
## Missouri       0.383674183 1.373429e-01 7.831126e-01 5.763331e-01
## Montana        1.110529158 5.707807e-01 3.350612e-01 1.730484e-01
## Nebraska       1.265843739 7.449381e-02 1.694492e-01 2.854547e-03
## Nevada         6.529122930 1.191241e+00 7.439832e+00 1.117933e+00
## New Hampshire  4.491007385 6.474866e-04 7.466579e-03 1.240986e-02
## New Jersey     0.026051436 4.160675e+00 3.212342e+00 6.694390e-01
## New Mexico     3.098153195 4.040890e-02 1.854816e-01 1.302858e+00
## New York       2.237237951 1.341893e+00 2.273228e+00 2.054910e-03
## North Carolina 0.997273744 9.830047e+00 4.099364e+00 1.029380e+01
## North Dakota   7.075396141 7.108040e-01 4.989446e-01 7.290473e-01
## Ohio           0.040350235 1.090964e+00 5.330062e-03 2.538249e+00
## Oklahoma       0.076818628 1.640851e-01 1.288422e-03 1.206500e-03
## Oregon         0.002762240 5.804687e-01 4.855354e+00 6.389764e-01
## Pennsylvania   0.623727164 6.458754e-01 8.822745e-01 1.457030e+00
## Rhode Island   0.589603965 4.408075e+00 1.031636e+01 4.254603e+00
## South Carolina 1.378434386 7.402347e+00 4.964983e-01 1.953273e-01
## South Dakota   3.122456990 1.342412e+00 8.330547e-01 1.356841e-01
## Tennessee      0.789837389 1.465462e+00 1.944547e-01 4.817009e+00
## Texas          1.451206676 3.369236e-01 1.330979e+00 4.675387e+00
## Utah           0.239540913 4.287925e+00 4.742533e-01 7.657368e-02
## Vermont        6.201774575 3.894022e+00 3.890301e+00 2.372509e-01
## Virginia       0.007333807 7.900117e-02 7.540878e-04 5.049189e-01
## Washington     0.037178745 1.863711e+00 2.146348e+00 5.512108e-01
## West Virginia  3.513536592 4.020316e+00 6.034374e-02 1.966434e-01
## Wisconsin      3.417978990 7.399257e-01 1.059998e-01 3.830512e-01
## Wyoming        0.313077863 2.040653e-01 3.183645e-01 3.138713e-01</code></pre>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">res.ind</span><span class="op">$</span><span class="va">cos2</span>           <span class="co"># Quality of representation </span></span></code></pre></div>
<pre><code>##                      Dim.1        Dim.2        Dim.3        Dim.4
## Alabama        0.392030990 5.184533e-01 0.0796600695 9.855631e-03
## Alaska         0.408542467 1.237310e-01 0.4470626440 2.066384e-02
## Arizona        0.712223835 1.274849e-01 0.0006875249 1.596038e-01
## Arkansas       0.015145647 9.496046e-01 0.0099410946 2.530862e-02
## California     0.690465216 2.580267e-01 0.0388311881 1.267690e-02
## Colorado       0.513382675 2.182676e-01 0.2683492506 4.802583e-07
## Connecticut    0.533580506 3.427557e-01 0.1196068911 4.056943e-03
## Delaware       0.001622998 7.548094e-02 0.3682358713 5.546602e-01
## Florida        0.963538193 1.633286e-04 0.0353145274 9.839511e-04
## Georgia        0.479890482 2.921031e-01 0.0209437358 2.070626e-01
## Hawaii         0.202321566 5.990742e-01 0.0006263898 1.979778e-01
## Idaho          0.881605007 1.459304e-02 0.0221296805 8.167227e-02
## Illinois       0.669460010 1.636887e-01 0.1616089288 5.242321e-03
## Indiana        0.500166418 4.496995e-02 0.1018162706 3.530474e-01
## Iowa           0.992531591 2.115880e-03 0.0052922975 6.023097e-05
## Kansas         0.845225119 9.714994e-02 0.0008691196 5.675582e-02
## Kentucky       0.291688374 4.752612e-01 0.0004163927 2.326340e-01
## Louisiana      0.607906870 1.883650e-01 0.1523932127 5.133492e-02
## Maine          0.957468445 2.361185e-02 0.0007190317 1.820068e-02
## Maryland       0.856687080 5.038754e-02 0.0068126744 8.611271e-02
## Massachusetts  0.083986303 7.725494e-01 0.1320026372 1.146163e-02
## Michigan       0.960514018 5.217530e-03 0.0320041033 2.264349e-03
## Minnesota      0.870109037 1.213993e-01 0.0071155038 1.376167e-03
## Mississippi    0.135683684 7.829826e-01 0.0749876323 6.346068e-03
## Missouri       0.648795750 9.268084e-02 0.1903759837 6.814743e-02
## Montana        0.794043831 1.628628e-01 0.0344414327 8.651919e-03
## Nebraska       0.958877291 2.251860e-02 0.0184529144 1.511996e-04
## Nevada         0.800900045 5.831246e-02 0.1311985745 9.588918e-03
## New Hampshire  0.999510473 5.750591e-05 0.0002388954 1.931261e-04
## New Jersey     0.011868365 7.564168e-01 0.2103892385 2.132557e-02
## New Mexico     0.958573415 4.989277e-03 0.0082502273 2.818708e-02
## New York       0.721764161 1.727584e-01 0.1054310669 4.635606e-05
## North Carolina 0.160097282 6.297430e-01 0.0946081503 1.155516e-01
## North Dakota   0.945686444 3.791267e-02 0.0095871885 6.813693e-03
## Ohio           0.061701103 6.657261e-01 0.0011717141 2.714011e-01
## Oklahoma       0.538820960 4.592881e-01 0.0012992078 5.917466e-04
## Oregon         0.002826986 2.370714e-01 0.7143740849 4.572750e-02
## Pennsylvania   0.561820397 2.321613e-01 0.1142481193 9.177021e-02
## Rhode Island   0.142785918 4.260025e-01 0.3591648076 7.204677e-02
## South Carolina 0.312042985 6.687071e-01 0.0161580367 3.091874e-03
## South Dakota   0.824430972 1.414431e-01 0.0316208722 2.505055e-03
## Tennessee      0.454078924 3.362067e-01 0.0160714327 1.936429e-01
## Texas          0.689760646 6.390558e-02 0.0909458723 1.553879e-01
## Utah           0.118337750 8.453352e-01 0.0336818935 2.645170e-03
## Vermont        0.744368850 1.865129e-01 0.0671271140 1.991180e-03
## Virginia       0.098738949 4.244541e-01 0.0014595649 4.753474e-01
## Washington     0.032959393 6.593276e-01 0.2735440166 3.416903e-02
## West Virginia  0.683526318 3.121110e-01 0.0016876620 2.674980e-03
## Wisconsin      0.910180221 7.862928e-02 0.0040579405 7.132558e-03
## Wyoming        0.677323391 1.761777e-01 0.0990172499 4.748165e-02</code></pre>

</div>
</div>
  <div class="chapter-nav">
<div class="empty"></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>MULTIVARIATE DATA ANALYSIS TOOLS FOR AGRICULTURAL RESEARCH</strong>" was written by Dr. PRATHEESH P GOPINATH. It was last built on 2023-10-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
