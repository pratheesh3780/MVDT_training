# Principal Component Analysis  

## What is PCA?
Principal component analysis (PCA) is a technique that transforms high-dimensions data into lower-dimensions while retaining as much information as possible.  

Drawing meaningful inferences from high-dimensional data can be challenging, as humans naturally excel at visualizing and comprehending information in two dimensions. PCA, a powerful technique, aids in transforming multi-dimensional data into a more manageable form by reducing its dimensionality. This simplification facilitates easier visualization and analysis, ultimately enhancing our ability to extract valuable insights from complex datasets.  

PCA is a valuable tool in social science and agricultural research. It works by transforming multi-dimensional data into a lower-dimensional space while retaining as much variance in the data as possible. In essence, PCA identifies the most significant dimensions or "principal components" of the data, effectively reducing its complexity.
The idea of PCA is simple — reduce the number of variables of a data set, while preserving as much information as possible.  

## When to Use PCA  

**Dimensionality Reduction**: Use PCA when you have a high-dimensional dataset with many features (variables) and you want to reduce its dimensionality. This can help in cases where you have too many variables to work with efficiently.  

**Data Visualization**: PCA is effective when you need to visualize high-dimensional data. By projecting data onto a lower-dimensional space, you can create scatter plots, heatmaps, or other visualizations that are easier to interpret.  

**Minimum data set**: Principal components can be used to eliminate some data sets and identify a minimum data set for further experimentation.  

**Noise Reduction**: If your dataset contains noisy or redundant features, PCA can help by capturing the most important information and eliminating the less relevant components.  

**Multicollinearity**: When your dataset has multicollinearity issues (high correlations between variables), PCA can help reduce these interdependencies, making models more stable and interpretable.  

Sample size (n) should be at least equal to number of dimensions (n ≥ p)

## When Not to Use PCA  

When the **sample size** is less than number of dimensions (n < p)  

**Non-Linear Relationships**: PCA is based on linear transformations and may not be effective when your data contains complex non-linear relationships. In such cases, techniques like kernel PCA or other non-linear dimensionality reduction methods might be more appropriate.  

**Small Dimensionality**: If you already have a low-dimensional dataset with only a few important variables, applying PCA might not provide significant benefits and could even lead to information loss.  

**Loss of Variability Information**: PCA aims to maximize variance capture, which may not be desirable in some cases. If preserving other characteristics of the data is more important (e.g., categorical information), other dimensionality reduction techniques should be considered.  

## How PCA is done
In this training program, we are primarily focused on the practical application of PCA rather than delving into its theoretical aspects. Our aim is to explore when and how PCA can be effectively utilized and to understand how to interpret the results in a meaningful manner.  

-Standardize the range of continuous initial variables  
-Compute the covariance matrix to identify correlations  
-Compute the eigen vectors and eigen values of the covariance matrix to identify the principal components  
-Create a feature vector to decide which principal components to keep -Recast the data along the principal components axes  

## What is Principal Component  

Principal components are new variables that are constructed as linear combinations of the initial variables. These combinations are done in such a way that the new variables (i.e. principal components) are uncorrelated and most of the information within the initial variables are included in the first components. So, the idea if 10-dimensional data gives you 10 principal components, but PCA tries to put maximum possible information in the first component, then maximum remaining information in the second and so on. In the scree plot below you can see 5 principal components of a 5-dimensional data and the corresponding variance explained.  

```{r pcavar, echo=FALSE,fig.cap='Scree Plot: Principal components and percentage variance explained',out.width="70%", fig.align='center'}
knitr::include_graphics(rep("images/pcavar.png"))
```  

## How PCA Constructs the Principal Components  

Number of principal components are equal to the number of variables in the data, principal components are constructed in such a manner that the first principal component accounts for the largest possible variance in the data set. For example, see the Figure 1.2 below, we can see the scatter plot of our assumed data set, can we guess the first principal component ? Yes, it’s approximately the line that matches the purple marks because it goes through the origin and it’s the line in which the projection of the points (red dots) is the most spread out. Or mathematically speaking, it’s the line that maximizes the variance (the average of the squared distances from the projected points (red dots) to the origin).  
```{r pcagif, echo=FALSE,fig.cap='Concept of PCA',out.width="100%", fig.align='center'}
knitr::include_graphics(rep("images/pca.gif"))
```   
These lines (PCs) were identified using linear algebra concepts Eigen vectors and eigen values which are calculated from the covariance matrix in order to determine the principal components of the data. We are not going much in to theoretical details. 

## PRACTICAL EXAMPLE
We will be using Usarrests dataset in R to explain PCA in the coming sessions.The "USarrests" dataset in R is a built-in dataset that offers insights into crime and arrests across the 50 states of the United States in 1973. It comprises four key variables: murder rate, assault rate, the percentage of the population living in urban areas, and the rape rate. 

You can View and download the datasets here
```{r usarrest, eval=TRUE, echo=FALSE}
library(DT)

datatable(
  USArrests,
  extensions = 'Buttons',
  options = list(
    dom = 'Bfrtip',
    buttons = list(
      list(
        extend = 'csv',
        filename = 'data'
      )
    ),
    searching = FALSE  # This option removes the search bar
  )
)


```

